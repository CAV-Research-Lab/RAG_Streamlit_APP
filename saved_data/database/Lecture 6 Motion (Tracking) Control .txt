=== Metadata ===
{
    "file_name": "Lecture 6 Motion (Tracking) Control .pdf",
    "file_path": "/Users/mf0016/Desktop/soe_RAG/resources/Lecture 6 Motion (Tracking) Control .pdf",
    "status": "Processed"
}

=== Content ===
Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah   Motion (Tracking) Control  Introduction to Motion Control To start, let’s first answer the question: What Is Motion Control? The answer is: “Motion control, also known as tracking control, refers to the fact that a control system should be able to track the desired reference trajectory which is generated by motion planning module. In other words, the car should follow the reference trajectory as close as possible, with minimal transient and/or steady state error (zero in ideal case). In simpler words, Motion Control is how the intelligent car uses the steering, throttle, and breaks to drive where we want it to go. Control is a trickier problem than it might seem. When human turns through an intersection, we use our intuition and experience to determine how hard to steer, and when to accelerate, and whether we ever need to step on the brakes. Teaching a computer how to do this is hard. In this lecture, you'll learn how to implement a motion controller using different control systems.  First let’s review what control methods that can be used for motion control. The controllers used for motion control or trajectory tracing can be classified as model-free and model-based controllers.  1. Model-Free Controllers: These controllers do not utilise any mathematical model of the system being controlled. Instead, they take 'corrective' action based on the 'error' between the setpoint and the current state. Such controllers are relatively easy to implement, as they do not require a deep understanding of the system's behaviour; however, they are difficult to tune, do not guarantee optimal performance, and tend to perform satisfactorily only under limited operating conditions. Common examples of these types of controllers include PID and Stanley controllers. 2. Model-Based Controllers: These controllers employ various types of mathematical models of the system being controlled. Typically, they offer optimal actions, are straightforward to tune, and are easy to implement. However, their practical operation is limited to certain driving and operational conditions due to sensitivity to parameter variations and model accuracy. Model-based controllers can be further classified as: § Kinematic Controllers: These controllers utilise simplified motion models of the system, based on its geometry and kinematics, generally employing first-order approximations. They assume no slip or skip and often ignore internal or external forces acting on the system. Consequently, these types of controllers are typically limited to low-speed applications, where the system dynamics can be reasonably approximated. However, they offer the advantage of low computational complexity, which is extremely significant in real-world implementations as opposed to theoretical formulations or simulations. § Dynamic Controllers: These types of controllers utilise detailed motion models of the system, based on system dynamics. They consider forces and torques acting on the system, as well as any disturbances (incorporated into the dynamic model). Therefore, these types of controllers have an advantage over kinematic controllers due to the unrestricted Operational Design Domain (ODD), but they incur higher computational complexity due to the complex calculations involving detailed models at each timestep.  In the following sections, we will discuss the most well-known model-free controllers, including PID and Stanley controllers, and then formulate the kinematic model of an intelligent vehicle for model-based control systems. PID Control  PID control represents a vast area within the field of control systems, meriting numerous classes on this singular subject matter alone. You already know how PID control operates and how we can design a PID controller. In this lecture, however, we will delve into designing a PID controller specifically for controlling the motion of an intelligent vehicle. The approach we 
Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah   will explore has been adopted by many intelligent vehicle manufacturers, including Google Waymo, offering a glimpse into the essence of automotive control. Consider the following problem: a car equipped with a steerable front axle and two non-steerable rear wheels needs to follow the reference line shown in Figure 1, which is the output from the previously discussed motion planner. Assuming the car maintains a constant forward speed, but you have the capability to adjust the steering angle, how would you proceed? Would you keep the steering angle constant? Would you issue random steering commands? Alternatively, you could adjust the steering angle in proportion to the "cross-track error" (CTE), which is the lateral distance between the vehicle and the reference trajectory. The optimal strategy involves steering in proportion to the cross-track error. The larger the error, the more the steering should adjust towards the target trajectory, decreasing as the vehicle approaches the trajectory. Clearly, maintaining a constant steering angle would only lead the vehicle in circles, not along a straight line, while random steering commands would be dangerous.   
 Figure 1 The concept of trajectory tacking (motion) control. The 'P-controller', where 'P' stands for proportional, represents the simplest form of a controller. Here’s a thought-provoking question that tests your intuition—it doesn’t have a unique answer, but there is a best one. Suppose you steer the car in proportion to the cross-track error, as shown in Equation 1:   𝛿=𝜏!⋅𝐶𝑇𝐸 (1)  This means your steering angle is determined by multiplying the cross-track error by a factor of 𝜏!. What outcome would this approach likely yield? Does the car never quite reach the reference trajectory, does it overshoot, or could either outcome occur? The answer, interestingly, is that it tends to overshoot. The issue is that, regardless of how small the constant, 𝜏! in Equation 1 might be, it eventually causes significant wheel adjustment toward the trajectory. As the vehicle approaches this trajectory, and even as it aligns with it, the car’s orientation will still be slightly off, compelling it to overshoot. This demonstrates that a P-controller, when applied to a car, causes overshoots. Although these might be minor and potentially manageable, the system never truly stabilises but remains 'marginally stable' or, as often referred in literature, 'stable.' The next pertinent question is, 'Is there a way to avoid the overshoot?' Ideally, yes, because experiencing oscillation while driving is unpleasant and can induce discomfort. The solution lies in 'PD-control.' In PD-control, the steering angle, 𝛿, is influenced not only by the cross-track error through the gain parameter 𝜏! but also by the temporal derivative of the cross-track error as:   𝛿=	−𝜏!.𝐶𝑇𝐸−𝜏".##$(𝐶𝑇𝐸) (2) 

Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah    This means that as the car effectively reduces the cross-track error, it anticipates the reduction, facilitating counter-steering. This enables a more graceful alignment with the target trajectory, given the correct adjustment of the differential gain 𝜏" relative to the proportional gain 𝜏!. How to compute the derivative of the cross-track error in Equation 2? At any given time 𝑡, this is calculated as the difference between the cross-track error at time 𝑡 and the cross-track error at time 𝑡−1, divided by the time interval between 𝑡 and 𝑡−1. The mathematical formulation is as follows:   ##$(𝐶𝑇𝐸)=%&'!(%&'!"#)$ (3)  Now, we control not just in proportion to the error itself but also in relation to the change in error, using a second constant, 𝜏".  Can the differential term alone solve the problem of achieving perfect trajectory alignment? The answer is no. Why is that? Consider driving a car where your usual steering adjustments lead you significantly astray from the desired trajectory. Over time, you notice the vehicle doesn't get closer to the goal, prompting you to increasingly correct your steering to the right to offset this bias. This requires a consistent situation of a large error, which is captured by the integral or the sum of the cross-track errors over time. Let's introduce a new controller type, where steering is still proportional to the cross-track error and its differential, but now it also includes a term proportional to the integral or the sum of all observed cross-track errors. This integral term is particularly interesting. If we have a constant cross-track error of, for example, 0.8, the sum will increase by 0.8 with each time unit, growing larger and larger, and eventually, it will correct the vehicle's motion. This introduces the PID controller, encompassing the Proportional (P), Integral (I), and Differential (D) terms. Implementing this, the integrated cross-track error is the cumulative sum of all cross-track errors observed. The mathematical representation of PID controller is:   𝛿=−𝜏*.𝐶𝑇𝐸−𝜏".##$(𝐶𝑇𝐸)−𝜏".∫(𝐶𝑇𝐸)𝑑𝑡 (4)  Initially, the gains of the PID controller need to be manually tuned. A general rule of thumb is to start with the 𝜏+ and 𝜏" values set to zero and adjust the 𝜏* value until the system begins to oscillate around the setpoint. Then, the 𝜏" value is fine-tuned until the oscillations are mostly damped out. Finally, the 𝜏+ value is adjusted to minimise any steady-state error. To further refine the gains, an optimisation algorithm (such as twiddle or gradient descent) can be used for iterative adjustments. The characteristics of the controller gains—namely, the effects of gain amplification on the closed-loop system response for the proportional, integral, and derivative terms of the PID controller—are summarised in Table 1. This information is invaluable for tuning the controller gains to achieve the desired system response.        In essence, the P controller aims to correct the present error with a control action proportional to it. The I controller addresses any accumulated past error with a control action proportional to the cumulative error over time. The D controller anticipates future error by generating a control action proportional to the rate of change of the error. It is important to note that the 
𝜏"=0 𝜏+=0 𝜏*	↑ 
𝜏"↑ 𝜏+=0 𝜏*:		𝑓𝑖𝑥𝑒𝑑 
𝜏":	𝑓𝑖𝑥𝑒𝑑 𝜏+			↑ 𝜏*:		𝑓𝑖𝑥𝑒𝑑 Table 1. PID Tunning 
Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah   integral and derivative controls are not standalone; they are designed to complement the proportional control. Stanley control Stanley controller is a geometric trajectory tracking controller developed by Stanford Racing Team for their autonomous vehicle “Stanley” at the DARPA Grand Challenge (2005). Stanley controller uses both heading as well as cross-track errors to determine the steering action. As shown in Figure 2, the cross-track error CTE is defined with respect to a closest point on the reference trajectory whereas the heading error 𝑒, is defined using the vehicle heading relative to the reference trajectory.  
 Figure 2 State configuration for Stanley control.  If we consider the centre of the front axle of the vehicle as the frame of reference, we have the geometric relations as shown in Figure 2, where, the vehicle wheelbase is 𝐿, forward velocity of the ego vehicle is 𝑣- , and steering angle of the intelligent vehicle is 𝛿.  Stanley controller uses both heading as well as cross-track errors to determine the steering command. It is noted that the steering angle generated by the controller must observe the steering actuation limits. Stanley control law is essentially defined to meet three requirements.  The first requirement of Stanley controller, as represented in Equation (5), is to correct the heading error by producing a steering control action 𝛿 proportional (or equal) to it, such that vehicle heading aligns with the desired heading.    𝛿=𝑘,𝑒,	 (5)  The second requirement is to correct the cross-track error by producing a steering control action 𝛿 directly proportional to it and inversely proportional to the vehicle velocity 𝑣- in order to achieve simultaneous control of longitudinal and lateral motions of the car. In Stanley controller, the effect for large cross-track errors is limited by using an inverse tangent function:   𝛿=tan(.>/$%&.%&'1'? (6)   By closely looking at the Equation (6), there is a practical problem in implementation of the controller. In fact, the inverse relation between steering angle and vehicle speed can cause numerical instability in control actions. At lower speeds, the denominator becomes small which causes the steering command to shoot to higher values, which is undesirable considering human comfort. Hence, an extra softening coefficient may be used in the denominator as an additive term in order to keep the steering commands smaller for smoother steering actions. On the contrary, at higher velocities, the denominator becomes large making the steering 

Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah   commands small to avoid large lateral accelerations. However, even these small steering actions might be high in some cases which causes high lateral accelerations. Therefore, an extra damping coefficient may be used in order to dampen the steering action proportional to vehicle velocity. Therefore, the modified control formulation is:   𝛿=tan(.>/$%&.%&'/(2/).1'? (7)   The third requirement is to continuously observe the steering actuation limits [−𝛿345,𝛿345] and clip the steering command within these bounds. Using these three requirements, we can formulate the complete Stanley control law.    𝛿=𝑘,𝑒,+tan(.>/$%&.%&'/(2/).1'?;	𝛿∈[−𝛿345,𝛿345,]	 (8) It is noted that Stanley controller acts as a geometric proportional controller of steering angle 𝛿 operating on the heading error as well as the cross-track error, while observing the steering actuation limits.  Using Equation (8), two important inputs for the Stanley controller are the heading angle error and the cross-track error. Now, the question arises: how can these inputs be calculated? The equations for the errors are as follows:   𝑒,=𝜃−𝜃67- (9)  𝐶𝑇𝐸=𝑦−𝑦67- (10)  In fact, the heading angle error is the difference between the actual heading angle of the car and the reference heading angle, which is calculated from the reference trajectory. Similarly, the cross-track error is the difference between the actual lateral position of the car and the reference lateral position. However, the reference trajectory provided by the motion planner is in Frenet coordinates, while the vehicle's sensor measurements are in Cartesian coordinates. Therefore, the reference trajectory in Frenet coordinates needs to be transformed into Cartesian coordinates. Transforming from Frenet coordinate into Cartesian coordinates is not trivial. The details of the transformation procedure are beyond the scope of this lecture, but final relations will be discussed. 
 Figure 3 Transformation from Frenet frame to Cartesian frame. 

Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah   When in the Cartesian frame, we can describe the current state of the ego vehicle as [𝑥⃗,𝜃5	,𝜅5,𝑣5,𝑎5], where 𝑥⃗ represents the vehicle’s position at 𝑄(𝑥,𝑦), and 𝑛M⃗𝑥 and 𝑡⃗𝑥 are the unit normal and tangent vectors of the vehicle’s motion trajectory at the position 𝑄 (see Figure 3). Additionally, 𝜃5 denotes the angle between 𝑥⃗ and the x-axis, 𝜅5 represents the curvature at 𝑄, 𝑣5 is the velocity of the ego vehicle, and 𝑎5 is the vehicle’s acceleration. On the other hand, in a Frenet frame, the point 𝑃 represents the projection of the vehicle’s position point 𝑄 onto the reference line. The angle between 𝑟⃗ and the x-axis is denoted by 𝜃6, while	𝑛M⃗6 and 	𝑡⃗6 denote the unit normal and tangent vectors of the reference line at point 𝑃. The vehicle’s status can typically be described using the vector [𝑠,𝑠̇,𝑠̈,𝑑,𝑑̇,𝑑̈,𝑑8,𝑑"] where the distance between 𝑃 and 𝑄 corresponds to the transverse displacement 𝑑, and the curve distance from the start point of the reference line to 𝑃 represents the longitudinal displacement 𝑠. Additionally, 𝑑′ denotes the first derivative of 𝑑 with respect to 𝑠 while 𝑑" denotes the second derivative of 𝑑 with respect to 𝑠. Then, the equation of vehicle status in the Cartesian frame can be written as follows:   
  (11) Where ∆𝜃	=	𝜃𝑥	−	𝜃𝑟; 𝜅𝑟 is the curvature at point P. Kinematic Model-based Motion Control Kinematics is the study of motion of a system disregarding the forces and torques that govern it. Kinematic models can be employed in situations wherein kinematic relations are able to sufficiently approximate the actual system dynamics. It is important to note, however, that this approximation holds true only for vehicles that perform non-aggressive manoeuvres at lower speeds. To quote an example, kinematic models can nearly-accurately represent a vehicle driving slowly and making smooth turns. However, if we consider something like a racing car, it is very likely that the kinematic model would fail to capture the actual system dynamics.  In this part of lecture, the most widely used kinematic model for intelligent vehicles, the kinematic bicycle model, will be introduced. This model performs well at capturing the actual vehicle dynamics under nominal driving conditions. In practice, this model tends to strike a good balance between simplicity and accuracy and is therefore widely adopted. The idea is to define the vehicle state configuration and see how it evolves over time based on the previous state and current control inputs given to the vehicle.  Let’s define the vehicle state configuration as 𝑥 and 𝑦 components of position and heading angle or orientation. Summarising, the intelligent vehicle state vector 𝑞 as this:    𝑞=[𝑥𝑦			𝜃] (12)  For control inputs, we need to consider both longitudinal (throttle and brake) and lateral (steering) commands. The brake and throttle commands contribute to longitudinal accelerations in range of [−𝑎𝑚𝑎𝑥,𝑎𝑚𝑎𝑥] where negative values represent deceleration due to braking and positive values represent acceleration due to throttle (forward or reverse depending upon the transmission state). Note that the limits [−𝑎𝑚𝑎𝑥,𝑎𝑚𝑎𝑥] are intentionally denoted so as to distinctly illustrate the difference between the physical limits of acceleration 

Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah   due to throttle and deceleration due to braking. The steering command alters the steering angle δ of the vehicle, where 𝛿	∈	[−𝛿𝑚𝑎𝑥,𝛿𝑚𝑎𝑥] such that negative steering angles dictate left turns and positive steering angles otherwise. Note that generally, the control inputs are clamped in the range of [−1,1] based on the actuators for proper scaling of control commands in terms of actuation limits. However, in this kinematic model, the longitudinal control is ignored, and the focus is on vehicle lateral dynamic control. Therefore, the intelligent vehicle control vector 𝑢 is defined as 𝑢	=𝛿. Before deriving the equations, let’s define the parameters of the vehicle bicycle model as shown in Figure 4: 𝑣 represents vehicle longitudinal speed, 𝛿 is the vehicle wheel steering angle, 𝜃	is the vehicle heading angle, 𝐿 is vehicle wheel-base, 𝑙- and 𝑙6 are the distances of front and rear axles to the vehicle centre of gravity, respectively. 𝑣.sin𝜓 and 𝑣.cos𝜓 are the velocity vector 𝑣 into x and y components, respectively. ICR represents the vehicle instantaneous centre of rotation and R is the radius of the rotation. In this kinematic model, we assume no slip between tyres and the road.   
 Figure 4 Vehicle kinematic bicycle model.  Now let’s derive the equations for kinematic model. First, resolving the velocity vector 𝑣 into 𝑥 and 𝑦 components using the laws of trigonometry one obtains,    𝑥̇=𝑣.cos𝜃	 (13)  𝑦̇=	𝑣sin𝜃 (14)  In order to compute 𝜃̇, we first need to calculate R using this relation.   𝑅=9:;<(>) (15)   Now, we can deduce 𝜃̇ as:   𝜃̇=1@=1.:;<(>)9  (16) 

Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah    We can formulate the continuous-time kinematic model of our intelligent vehicle in a vector format1:   𝐱̇=a𝑥̇𝑦̇𝜃̇b=c𝑣.cos𝜃𝑣.sin𝜃1.:;<(>)9d (17)  After obtaining the equations for the kinematic model, we can now design a control system to enable the vehicle to follow the reference trajectories provided by the Motion Planning module using methods such as jerk minimisation. However, Equation (17) includes nonlinear functions, which make the control design non-trivial. To linearise the state equations, we can assume small angles for both heading and wheel steering. With this assumption, we have: cos𝜃≅1, sin𝜃≅𝜃 and tan𝛿≅𝛿. Therefore, the linearised dynamic model is:     a𝑥̇𝑦̇𝜃̇b=c𝑣.𝜃𝑣.𝜃19.𝛿d (18)  The kinematic model can be rewritten in matrix format, based on its inputs and states, as follows:   a𝑥̇𝑦̇𝜃̇b=a00000𝑣000b  f𝑥𝑦𝜃g + c0019d 𝛿+ f𝑣00g (19)  The compact representation of the kinematic model is:   𝐱̇(𝑡)=𝐴(𝑣)𝐱(𝑡)+𝐵.(𝑣)𝑢(𝑡)+𝐵A(𝑣) (20)   The obtained linear model is a time-vary system as the system matrix, 𝐴 and input vector 𝐵. are function of vehicle speed. To design a control system using the kinematic model represented by Equation (20), we need to use the advanced control techniques. To make the control design problem simpler, we can assume that the vehicle speed is constant. In this case, the kinematic model will be time-invariant and therefore, we can ignore the longitudinal dynamic. In this case, Equation (20) can be simplified as:    𝐱̇(𝑡)=j𝑦̇𝜃̇k=f𝑣.	𝜃19𝛿g (21) or   j𝑦̇𝜃̇k=l0𝑣00ml𝑦𝜃m+ f019g 𝛿 (22)  Then the compact matrix representation of Equation (22) is:  1 Please note, the parameters presented in lowercase, non-italic, bold format represent vectors. Those in lowercase, italic, but not bold, represent scalars, and those in uppercase, italic, but not bold, represent matrices. 
Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah    𝐱̇(𝑡)=𝐴𝐱(𝑡)+𝐵𝑢(𝑡) (23)  𝐲=𝐶𝐱(𝑡) (24) Where, 𝐲 is the output vector:   𝒚=l𝑦𝜃m=l1001ml𝑦𝜃m (25) The objective is to design a controller that minimises the error between the reference trajectory and the actual vehicle trajectory. Therefore, the first step is to define the error vector 𝐞(𝑡) as:    𝐞(𝑡)=𝐱(𝑡)−𝐱67-(𝑡)  (26) where, 𝐱67-(𝑡) is the reference trajectory, and 𝐱(𝑡) is the actual vehicle state. The derivate of error vector is:  𝐞̇(𝑡)=𝐱̇−𝐱̇67-  (27) By substituting Equation (23) into Equation (27), we have:  𝐞̇(𝑡)=𝐴𝐱(𝑡)+𝐵𝑢(𝑡)−𝐱̇67-(𝑡) (28) By rearranging Equation (26), we can calculate state vector based on error vector as:  𝐱(𝑡)=𝐞(𝑡)+𝐱67-(𝑡) (29) By substituting 𝐱(𝑡) into Equation (28), we have:  𝐞̇(𝑡)=𝐴𝐞(𝑡)+𝐵𝑢(𝑡)+𝐴𝐱67-(𝑡)−𝐱̇67-(𝑡)  (30) where, 𝐴𝐱67-(𝑡)−𝐱̇BCD(𝑡) represents how the reference trajectory inherently changes over time (and assuming it does not directly depend on the system's state 𝐱(𝑡) or the control input 𝑢(𝑡)). The term 𝐴𝐱67-(𝑡)−𝐱̇BCD(𝑡) can be seen as an external input or disturbance to the error dynamics, influenced by the trajectory's predefined behaviour. Therefore, a more nuanced view is that the control law needs to counteract not just the state 𝐱(𝑡) deviations from 𝐱67-(𝑡) but also the rate at which 𝐱67-(𝑡) itself changes. Therefore, we need two controllers, one is the feedback control and another is feedforward control. The feedback control is responsible for compensating for any deviations from the reference trajectory by adjusting the input (steering angle) based on the error while the feedforward controller aims to anticipate the reference trajectory and provide the necessary input to follow it precisely. Therefore, the control law will be:  𝑢(𝑡)=−𝐊𝐞(𝑡)+𝑢EE (31) where, =−𝐊𝐞(𝑡) is the feedback control law and 𝑢EE is the feedforward control. Therefore, the error dynamics equation will be:  𝐞̇(𝑡)=𝐴𝐱(𝑡)+𝐵[−𝐊𝐞(𝑡)+𝑢EE]+𝐴𝐱67-(𝑡)−𝐱̇67-(𝑡) (32) 
Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah   We can design the feedback controller, 𝐊, using different feedback control techniques such as pole placement, optimal control or model predictive control (MPC). The calculation of the feedforward control term, 𝑢EE, is a crucial aspect of ensuring the vehicle precisely follows the reference trajectory. This term is designed to anticipate the necessary control actions to maintain the trajectory, considering the inherent changes in the trajectory over time. Specifically, 𝑢EE is calculated by isolating the feedforward term in the control law equation and ensuring the system's error dynamics are addressed in the steady-state condition (where 𝑒(𝑡)→0 as 𝑡→∞). Therefore, in steady state condition, we have:  𝟎=𝟎+𝐵[𝟎+𝑢EE]+𝐴𝐱67-(𝑡)−𝐱̇67-(𝑡)  (34) By reshaping above equation, the feedforward controller can be formulated as:  𝑢EE=𝐵(𝟏u𝐱̇67-(𝑡)−𝐴𝐱67-(𝑡)v (35) where, 𝐵(. represents the inverse of the input matrix B, enabling us to compute the direct influence of the reference trajectory’s dynamics on the control input. In essence, 𝑢EE functions to proactively adjust the vehicle's steering angle according to the planned changes in the reference trajectory, rather than reacting to deviations after they occur. This proactive approach is fundamental in achieving smoother and more accurate trajectory tracking, especially in scenarios where the vehicle's dynamics and the desired trajectory involve complex manoeuvres or rapid changes in direction. Model Predictive Control  Model Predictive Control (MPC) is a type of optimal control strategy that basically treats the control task as a constrained or bounded optimisation problem. MPC is a powerful method for designing motion control systems for intelligent vehicles and has been widely used by industry.  But how MPC works? Model predictive controller predicts the future states of the vehicle up to a certain prediction horizon using the motion model and then solves an online optimisation problem considering the constraints or control bounds in order to select the optimal set of control inputs by minimising a cost function such that the future state(s) of the intelligent vehicle closely align with the goal state (as required for trajectory tracking).  In other words, given the current state and the reference trajectory to follow, MPC involves simulating different control inputs (without actually applying them to the system), predicting the resulting future states (in form of a predicted trajectory) using motion model up to a certain prediction horizon, selecting the optimal set of control inputs corresponding to minimal cost trajectory (considering constraints) at each step in time, and applying the very first set of optimal control inputs (up to a certain control horizon) to the intelligent vehicle, discarding the rest. With the updated state, we again repeat the same algorithm to compute a new optimal predicted trajectory up to the prediction horizon. In that sense, we are computing optimal control inputs over a constantly moving prediction horizon. Thus, this approach is also known as receding horizon control. Figure 5 depicts the structure of an MPC controller.  
Intelligent Vehicle Design (ENGM298) – Prof Saber Fallah    Figure 5 The structure of MPC.  

